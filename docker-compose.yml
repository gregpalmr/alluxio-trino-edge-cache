version: '3.7' 

services:

  trino-coordinator:
    image: mytrino/trino-alluxio-edge
    hostname: trino-coordinator
    container_name: trino-coordinator-dzi
    deploy:
      resources:
        reservations:
          memory: 6G
    networks:
      custom:
        ipv4_address: 172.26.0.10
    volumes:
      - trino-coordinator-data:/data
    expose:
      - 8080
    ports:
      - '8080:8080'
    command:
      - /bin/bash
      - -c 
      - |
        sed -i "s/coordinator=false/coordinator=true/" /etc/trino/config.properties
        sed -i "s/node-scheduler.include-coordinator=true/node-scheduler.include-coordinator=false/" /etc/trino/config.properties
        /usr/lib/trino/bin/run-trino

  trino-worker1:
    image: mytrino/trino-alluxio-edge
    hostname: trino-worker1
    container_name: trino-worker1-dzi
    shm_size: '1.5gb'
    deploy:
      resources:
        reservations:
          memory: 6G
    networks:
      custom:
        ipv4_address: 172.26.0.11
    volumes:
      - trino-worker1-data:/data
    expose:
      - 8080
    command:
      - /bin/bash
      - -c 
      - |
        sed -i "s/coordinator=true/coordinator=false/" /etc/trino/config.properties
        sed -i "s/node-scheduler.include-coordinator=true/node-scheduler.include-coordinator=false/" /etc/trino/config.properties
        echo "discovery.uri=http://trino-coordinator:8080" >> /etc/trino/config.properties
        /usr/lib/trino/bin/run-trino

  hive-metastore:
    image: docker.io/sslhep/hive-metastore:3.1.3
    hostname: hive-metastore
    container_name: hive-metastore-dzi
    user: root
    networks:
      custom:
        ipv4_address: 172.26.0.4
    environment:
      - SERVICE_NAME=metastore
    expose:
      - 9083
    ports:
      - 9083:9083
    volumes:
      - ./config-files:/tmp/config-files:ro
      - hive-metastore-data:/data
    entrypoint: >
      /bin/sh -c "
        cp /tmp/config-files/hive/metastore-site.xml /opt/hive/conf/metastore-site.xml
        if [ ! -d /opt/hive/metastore_db ]; then
          SKIP_SCHEMA_INIT="true"
        fi
        /entrypoint.sh
        sleep infinity
        "
  jupyter-lab:
    image: jupyter/pyspark-notebook:spark-3.2.1
      # NOTE: For Spark 3.2.1, use Delta Lake version 2.0.x (i.e !pip install delta-spark==2.0.1)
    hostname: jupyter-lab
    container_name: jupyter-lab-dzi
    user: root
    networks:
      custom:
        ipv4_address: 172.26.0.13
    ports:
      - 8888:8888
    volumes:
      - jupyter-lab-data:/home/jovyan/work
    entrypoint: >
      /bin/sh -c "
        if [ -d /tmp/local-files/ ] && [ -f /tmp/local-files/hadoop-aws-3.3.4.jar ]; then
          cp /tmp/local-files/hadoop-aws-3.3.4.jar /usr/local/spark/jars/ && \
          cp /tmp/local-files/aws-java-sdk-bundle-1.12.262.jar /usr/local/spark/jars/;
        else
          wget -q --directory-prefix=/usr/local/spark/jars/ https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.4/hadoop-aws-3.3.4.jar && \
          wget -q --directory-prefix=/usr/local/spark/jars/ https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.262/aws-java-sdk-bundle-1.12.262.jar;
        fi
        mkdir -p /home/jovyan/.jupyter/;
        echo 'c.ServerApp.password = "argon2:$$argon2id$$v=19$$m=10240,t=10,p=8$$kOWx6DB2+ax213XlHzCLBw$$Pw+uRsVfRzqVn4Zs7HphOZgGdPHIPxj\/+ZFWT\/6rxDI"' > /home/jovyan/.jupyter/jupyter_server_config.py;
        tini -g -- start-notebook.py;
        tail -f /dev/null
        "

  minio:
    image: 'minio/minio:latest'
    hostname: minio
    container_name: minio-dzi
    networks:
      custom:
        ipv4_address: 172.26.0.5
    expose:
      - 9000
    ports:
      - '9000:9000'
      - '9001:9001'
    volumes:
      - minio-data:/data
    environment:
      MINIO_ACCESS_KEY: minio
      MINIO_SECRET_KEY: minio123
    command: server --console-address ":9001" /data

  minio-create-buckets:
    image: minio/mc:latest
    container_name: minio-create-buckets-dzi
    networks:
      custom:
        ipv4_address: 172.26.0.6
    depends_on:
      - minio
    environment:
      MINIO_ACCESS_KEY: minio
      MINIO_SECRET_KEY: minio123
    entrypoint: >
      /bin/sh -c "
      sleep 5;
      /usr/bin/mc config host add myminio http://minio:9000 minio minio123;
      if [ \"`/usr/bin/mc ls myminio`\" == \"\" ]; then 
         echo \"Creating bucket myminio/minio-bucket-1\" && \
         /usr/bin/mc mb myminio/minio-bucket-1 && \
         /usr/bin/mc policy download myminio/minio-bucket-1 && \
         /usr/bin/mc cp /etc/motd myminio/minio-bucket-1/user/hive/warehouse/.temp_file; 
      else 
         echo \"Bucket myminio/hive already exists, skipping create\"; 
      fi;
      exit 0
      "
  prometheus:
    image: prom/prometheus:v2.22.2
    container_name: prometheus-dzi
    hostname: prometheus
    domainname: docker.com
    networks:
      custom:
        ipv4_address: 172.26.0.8
    expose:
      - 9090
    ports:
      - 9090:9090
    volumes:
      - ./config-files/prometheus:/etc/prometheus
      - prometheus-data:/prometheus
    command: --web.enable-lifecycle --log.level=debug --config.file=/etc/prometheus/prometheus.yaml

  grafana:
    image: grafana/grafana-oss:10.0.4
    networks:
      custom:
        ipv4_address: 172.26.0.9
    container_name: grafana-dzi
    hostname: grafana
    domainname: docker.com
    ports:
      - 3000:3000
    volumes:
      - ./config-files:/tmp/config-files:ro
      - ./bootstrap/bootstrap-grafana.sh:/bootstrap.sh
    user: root
    entrypoint: ["/bootstrap.sh"]

volumes:
  mariadb-data:
    driver: local
  minio-data:
    driver: local
  trino-coordinator-data:
    driver: local
  trino-worker1-data:
    driver: local
  hive-metastore-data:
    driver: local
  jupyter-lab-data:
    driver: local
  prometheus-data:
    driver: local

networks:
  custom:
    driver: bridge
    ipam:
      driver: default
      config:
      - subnet: 172.26.0.0/16
        gateway: 172.26.0.1
